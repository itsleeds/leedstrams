---
format: gfm
execute: 
  echo: false
---

## Proprocessing

```{r}
library(tidyverse)
library(sf)
zones = pct::get_pct_zones("west-yorkshire")
zones_leeds = zones |> 
  filter(lad_name == "Leeds")
leeds_boundary_lad = st_union(zones_leeds)
leeds_boundary = leeds_boundary_lad
# For testing:
leeds_boundary = zonebuilder::zb_zone("Leeds", n_circles = 1)
```

### Plan

-   Download the town map dataset from Scottish Library: https://maps.nls.uk/os/townplans-england/leeds2.html
-   Digitise the tramway centerlines from there
-   Digitise the tram network from Alex's image data
-   Combine both datasets into a single tramway network
-   Bonus: track lines
-   Comparing with OSM

### Rail Map online data

![](images/paste-2.png)

See png-to-geojson.py

### Town plan data

Individuals tiles can be accessed from URLs such as https://mapseries-tilesets.s3.amazonaws.com/os/town-england/North/19/259898/168840.png

This is raster 'tile pyramids' - zoom level 19, tile coordinates 259898, 168840.

<!-- We can import this image: -->

```{r}
#| eval: false
u = "https://mapseries-tilesets.s3.amazonaws.com/os/town-england/North/19/259898/168840.png"
img = magick::image_read(u)
# # A tibble: 1 Ã— 7
#   format width height colorspace matte filesize density
#   <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>
# 1 PNG      256    256 sRGB       FALSE    54128 72x72
img_terra = terra::rast(u)
# Calculate extent based on XYZ tile coordinates (Web Mercator)
z <- 19
x <- 259898
y <- 168840
max_ext <- 20037508.34
tile_size <- (2 * max_ext) / (2^z)

xmin <- -max_ext + (x * tile_size)
xmax <- -max_ext + ((x + 1) * tile_size)
ymax <- max_ext - (y * tile_size)
ymin <- max_ext - ((y + 1) * tile_size)

terra::ext(img_terra) <- c(xmin, xmax, ymin, ymax)
terra::crs(img_terra) <- "EPSG:3857"
terra::plotRGB(img_terra)
mapview::mapview(img_terra)

# Create a lapply to import all tiles in the Leeds area:
x_extent = st_transform(leeds_boundary, 3857) |> st_bbox()
x_min_tile = floor((x_extent$xmin + max_ext) / tile_size) 
x_max_tile = ceiling((x_extent$xmax + max_ext) / tile_size)
y_min_tile = floor((max_ext - x_extent$ymax) / tile_size)
y_max_tile = ceiling((max_ext - x_extent$ymin) / tile_size)
tile_list = list()
for(x in (x_min_tile:x_max_tile)[1:10]) {
  for(y in (y_min_tile:y_max_tile)[1:10]) {
    n_tiles = length(tile_list) + 1
    u = glue::glue("https://mapseries-tilesets.s3.amazonaws.com/os/town-england/North/19/{x}/{y}.png")
    # Check URL exists:
    if(httr::http_error(u)) { next }
    img_terra = terra::rast(u)
    xmin <- -max_ext + (x * tile_size)
    xmax <- -max_ext + ((x + 1) * tile_size)
    ymax <- max_ext - (y * tile_size)
    ymin <- max_ext - ((y + 1) * tile_size)
    terra::ext(img_terra) <- c(xmin, xmax, ymin, ymax)
    terra::crs(img_terra) <- "EPSG:3857"
    # check with mapview: 
    mapview::mapview(img_terra)
    # Wait for 10 s to check:
    Sys.sleep(1)
    if (n_tiles == 1) {
      img_final = img_terra
    } else {
      img_final = terra::merge(img_final, img_terra)
    }
  }
}
plot(tile_list[[1]])
# Merge tiles
tile_list_collection = terra::sprc(tile_list)
leeds_tiles = terra::merge(tile_list_collection)
plot(leeds_tiles)
# transform to British National Grid
leeds_tiles = terra::project(leeds_tiles, "EPSG:27700")
# Save:
terra::writeRaster(leeds_tiles, "leeds_townplan.tif", overwrite=TRUE)
```

The general pattern is: https://mapseries-tilesets.s3.amazonaws.com/os/town-england/North/{z}/{x}/{y}.png

You can copy-paste that URL into QGIS 'XYZ Tiles' to access the tiles directly as shown below:

![](images/paste-1.png)

<!-- You can download the tiles using R as follows: -->

```{r}


```

```{r}
#| eval: false
# Note: failed
library(maptiles)
# Define the tile provider
nls_provider <- create_provider(
  name = "NLS_Town_Plans",
  url = "https://mapseries-tilesets.s3.amazonaws.com/os/town-england/North/{z}/{x}/{y}.png",
  citation = "National Library of Scotland"
)
central_leeds = leeds_boundary |>
  st_transform(27700) 

mapview::mapview(central_leeds)

# Get tiles
leeds_tiles <- get_tiles(
  x = central_leeds, 
  provider = nls_provider, 
  zoom = 11,
  crop = TRUE,
  cachedir = "./tiles"
)
list.files("./tiles")
# Plot tiles
plot_tiles(leeds_tiles)
```

You can also use the `ceramic` package to download tiles:

```{r}
#| label: ceramic-tiles
#| eval: false
library(ceramic)

# Get tiles for Leeds boundary
# Note: This requires a Mapbox API key to be set in the environment variable MAPBOX_API_KEY
# Sys.setenv(MAPBOX_API_KEY = "your_key_here")

# cc_location automatically selects a zoom level based on the extent
# We use the leeds_boundary object defined earlier
leeds_tiles_ceramic <- cc_location(leeds_boundary)

# Plot
if(requireNamespace("terra", quietly = TRUE)) {
  terra::plotRGB(leeds_tiles_ceramic)
  plot(st_geometry(leeds_boundary), add = TRUE, border = "red")
}

tiles = read_tiles(
  x = central_leeds,
  base_url = "https://mapseries-tilesets.s3.amazonaws.com/os/town-england/North/",
  zoom = 19
)
```

### Extracting tram network from image

The following Python code processes the image `images/paste-2.png` to extract the Leeds tram network lines (purple), skeletonizes them, and converts the result to LineStrings.

```{python}
#| label: extract-tram-network
#| eval: false
import cv2
import numpy as np
from skimage.morphology import skeletonize
from shapely.geometry import LineString
import geopandas as gpd
import matplotlib.pyplot as plt

# Load the image
image_path = 'images/paste-2.png'
img = cv2.imread(image_path)

if img is not None:
    # Convert to HSV color space
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    # Define color range for the Leeds tram network (purple/blue lines)
    # Note: These values are approximate and may need tuning based on the specific image
    # HSV range: Hue [0, 179], Saturation [0, 255], Value [0, 255]
    # Purple is roughly around 130-160 in OpenCV's Hue scale
    lower_purple = np.array([120, 50, 50])
    upper_purple = np.array([170, 255, 255])

    # Create a mask
    mask = cv2.inRange(hsv, lower_purple, upper_purple)

    # Skeletonize the mask (requires boolean input)
    # We divide by 255 to get 0/1 values
    skeleton = skeletonize(mask // 255)

    # Convert skeleton to vector representation (LineStrings)
    # This is a simplified approach using contours
    contours, _ = cv2.findContours(skeleton.astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

    lines = []
    for cnt in contours:
        # Contours are arrays of points (x, y)
        # We need at least 2 points to form a LineString
        if len(cnt) >= 2:
            points = cnt.squeeze().tolist()
            # Handle case where squeeze results in 1D array if only 1 point (though len check handles most)
            if isinstance(points, list) and len(points) >= 2 and isinstance(points[0], list):
                 lines.append(LineString(points))
            elif isinstance(points, list) and len(points) >= 2 and isinstance(points[0], (int, float)):
                 # Case with 2 points, squeeze might return list of lists or flat list depending on shape
                 # cnt shape is (N, 1, 2). squeeze -> (N, 2).
                 # If N=2, squeeze -> (2, 2).
                 lines.append(LineString(points))

    # Create a GeoDataFrame
    gdf = gpd.GeoDataFrame(geometry=lines)

    # Plotting for verification
    fig, ax = plt.subplots(1, 2, figsize=(12, 6))
    ax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    ax[0].set_title('Original Image')
    ax[1].imshow(skeleton, cmap='gray')
    ax[1].set_title('Skeletonized Network')
    plt.show()

    # Save to file (optional)
    # gdf.to_file("leeds_tram_skeleton.geojson", driver="GeoJSON")
else:
    print(f"Image not found at {image_path}")
```

## Research

-   Compare with historic economic and usage data
-   ...